{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y3atZ26GHyX",
        "outputId": "b997491f-b8fc-4abb-dd21-c122e574b6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from keras.models import load_model\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "# from google.colab import drive\n",
        "import os\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZJ2oE2Gh6X"
      },
      "outputs": [],
      "source": [
        "model = load_model('model_0.9900.h5')\n",
        "NGRAM = 4\n",
        "MAXLEN = 31\n",
        "\n",
        "alphabet = ['\\x00', ' ', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'á', 'à', 'ả', 'ã', 'ạ', 'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ó', 'ò', 'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ê', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ú', 'ù', 'ủ', 'ũ', 'ụ', 'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'í', 'ì', 'ỉ', 'ĩ', 'ị', 'ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'đ', 'Á', 'À', 'Ả', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ằ', 'Ẳ', 'Ẵ', 'Ặ', 'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ', 'É', 'È', 'Ẻ', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ', 'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự', 'Í', 'Ì', 'Ỉ', 'Ĩ', 'Ị', 'Ý', 'Ỳ', 'Ỷ', 'Ỹ', 'Ỵ', 'Đ']\n",
        "# alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUi-79fsIN6h"
      },
      "outputs": [],
      "source": [
        "# So a 5-grams contain at most 7*5 = 35 character (except one that has spell mistake)\n",
        "# add \"\\x00\" padding at the end of 5-grams in order to equal their length\n",
        "def _encoder_data(text, maxlen=MAXLEN):\n",
        "        # text = \"\\x00\" + text\n",
        "        x = np.zeros((maxlen, len(alphabet)))\n",
        "        for i, c in enumerate(text[:maxlen]):\n",
        "            x[i, alphabet.index(c)] = 1\n",
        "        if i < maxlen - 1:\n",
        "          for j in range(i+1, maxlen):\n",
        "            x[j, 0] = 1\n",
        "        return x\n",
        "      \n",
        "def _decoder_data(x):\n",
        "    x = x.argmax(axis=-1)\n",
        "    return ''.join(alphabet[i] for i in x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzZ7KDHvITKt",
        "outputId": "0d829099-a68c-4bbb-f226-11543acd2ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31, 199)\n",
            "Tôi tên là Việt Hoàng\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
          ]
        }
      ],
      "source": [
        "print(_encoder_data(\"Tôi tên là việt hoàng\").shape)\n",
        "print(_decoder_data(_encoder_data(\"Tôi tên là Việt Hoàng\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyCNmR_NITp1"
      },
      "outputs": [],
      "source": [
        "def _nltk_ngrams(sentence, n, maxlen):\n",
        "  list_ngrams = []\n",
        "  list_words = sentence.split()\n",
        "  num_words = len(list_words)\n",
        "  if num_words >= n:\n",
        "    for ngram in nltk.ngrams(list_words, n):\n",
        "      if len(' '.join(ngram)) <= maxlen:\n",
        "        list_ngrams.append(ngram)\n",
        "  else:\n",
        "    list_ngrams.append(tuple(list_words)) \n",
        "  return list_ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5w1lX0xJdft",
        "outputId": "49ac9980-3588-418b-a55b-0e41609d1fd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('xuwr', 'lys', 'ngoon', 'ngữ'),\n",
              " ('lys', 'ngoon', 'ngữ', 'tự'),\n",
              " ('ngoon', 'ngữ', 'tự', 'nhieen')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_nltk_ngrams('xuwr lys ngoon ngữ tự nhieen', NGRAM, MAXLEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VaTdK0qKAmS"
      },
      "outputs": [],
      "source": [
        "def _guess(ngram):\n",
        "  text = ' '.join(ngram)\n",
        "  preds = model.predict(np.array([_encoder_data(text)]))\n",
        "  return _decoder_data(preds[0]).strip('\\x00')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9aUDjSywLCGm",
        "outputId": "3f911ff8-99fb-4692-b1c2-6725997390f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Phạm văn đồngg nnưư  tưc'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_guess(('Phajm', 'vawn', 'ddoongf', 'nguwx', 'tuwj'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20IOFMEaQEkO"
      },
      "outputs": [],
      "source": [
        "def _add_punctuation(text, corrected_text):\n",
        "  list_punctuation = {}\n",
        "  for (i, word) in enumerate(text.split()):\n",
        "    if word[0] not in alphabet or word[-1] not in alphabet:\n",
        "      start_punc = ''\n",
        "      for c in word:\n",
        "        if c in alphabet:\n",
        "          break\n",
        "        start_punc += c\n",
        "      end_punc = ''\n",
        "      for c in word[::-1]:\n",
        "        if c in alphabet:\n",
        "          break\n",
        "        end_punc += c\n",
        "      end_punc = end_punc[::-1]\n",
        "      list_punctuation[i] = [start_punc, end_punc]\n",
        "  result = ''\n",
        "  for (i, word) in enumerate(corrected_text.split()):\n",
        "    if i in list_punctuation:\n",
        "      result += (list_punctuation[i][0] + word + list_punctuation[i][1]) + ' '\n",
        "    else:\n",
        "      result += word + ' '\n",
        "  return result.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNqOeGA4SWep"
      },
      "outputs": [],
      "source": [
        "def _correct(text):\n",
        "  new_text = re.sub(r'[^' + ''.join(alphabet) + ']', '', text)\n",
        "  # print('new_text: ', new_text)\n",
        "  ngrams = list(_nltk_ngrams(new_text, NGRAM, MAXLEN))\n",
        "  # print('ngrams: ', ngrams)\n",
        "  new_guessed_ngrams = list(_guess(ngram) for ngram in ngrams)\n",
        "  guessed_ngrams = []\n",
        "  for ele in new_guessed_ngrams: \n",
        "    x = ele.replace('  ', ' ')\n",
        "    guessed_ngrams.append(x)\n",
        "  # print('guessed_ngrams: ', guessed_ngrams)\n",
        "  candidates = [Counter() for _ in range(len(guessed_ngrams) + NGRAM - 1)]\n",
        "  # print('candidates: ', candidates)\n",
        "  for nid, ngram in (enumerate(guessed_ngrams)):\n",
        "    # print('nid: ', nid, ' ----- ngram: ', ngram)\n",
        "    for wid, word in (enumerate(re.split('\\s', ngram))):\n",
        "      # print('---> wid: ', wid, ' ----- word: ', word)\n",
        "      candidates[nid + wid].update([word])\n",
        "      # print('---> candidates_update: ', candidates[nid + wid].update([word]))\n",
        "  corrected_text = ' '.join(c.most_common(1)[0][0] for c in candidates if c)\n",
        "  print('text: ', text)\n",
        "  print('corrected_text: ', corrected_text)\n",
        "  return _add_punctuation(text, corrected_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBxlv0UUXZu",
        "outputId": "d10bd12a-95d4-486f-c79a-a73c910310de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  25 phan vawn ddajt, phuowfng beesn nghes, quaanj 1, thafnh phoos hoof chi minh\n",
            "corrected_text:  25 phân văn đạt phường bến nghe quân 1 thành phố hộ hhi mình\n",
            "text:  234 phajm vawn ddoofg, phuowfng linh trung, quaajn 2, thafnh phoos hoof chis minh\n",
            "corrected_text:  234 phạm văn đồng pphượng linh trung quân 2 thành phố hộ khí mình\n",
            "text:  23 hoaf bifnh phuowngf 3 quaanj 4\n",
            "corrected_text:  23 hoà bình phương 3 quân 4\n"
          ]
        }
      ],
      "source": [
        "text = ['25 phan vawn ddajt, phuowfng beesn nghes, quaanj 1, thafnh phoos hoof chi minh',\n",
        "        '234 phajm vawn ddoofg, phuowfng linh trung, quaajn 2, thafnh phoos hoof chis minh',\n",
        "        '23 hoaf bifnh phuowngf 3 quaanj 4'\n",
        "      ]\n",
        "# text = '25 phan vawn ddajt'\n",
        "# _correct(text)\n",
        "for ele in text:\n",
        "  _correct(ele)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Evaluate_model_checkspell.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
